# Choice of inference backend

There are multiple backends for executing models in the browser.  
In this decision I explore different options.

## Assumptions

-   This decision is tied to [the choice of inference framework](1.1-inference-framework.md). A decision might be made through choice of framework.

## Solutions

### WASM

Advantages:

-   Runs everywhere

Disadvantages:

-   (Too) slow

### WebGPU

Advantages:

-   Decent support
-   Quite stable (even though it's still experimental for chrome-linux and firefox)
-   Fast

Disadvantages:

-   Complex without frameworks/abstractions that compile to it

### [WebNN](https://webmachinelearning.github.io/webnn-intro/)

Advantages:

-   Fast

Disadvantages:

-   Experimental

### Other - TBD

## Decision

WebGPU seems to be the best option for now.

TDB
